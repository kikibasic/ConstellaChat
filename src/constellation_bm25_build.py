# constellation_bm25_build.py
# æ˜Ÿåº§ãƒ‡ãƒ¼ã‚¿ï¼ˆmyth_summary + keywords + best_monthsï¼‰ã‹ã‚‰
# BM25 ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã™ã‚‹ã ã‘ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚„RRFã¯ä¸€åˆ‡å«ã¾ãªã„ã€Œæˆæ¥­æº–æ‹ BM25ç‰ˆã€

import json
import math
import re
from collections import Counter
from pathlib import Path

import joblib
from fugashi import Tagger


# ================================================================
# è¨­å®š
# ================================================================

# æ˜Ÿåº§ãƒ‡ãƒ¼ã‚¿ï¼ˆã™ã§ã« keywords ä»˜ãã«ã—ãŸ JSONï¼‰
DATA_PATH = Path("./data/constellation_data_with_keywords.json")

# BM25ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
INDEX_DIR = Path("index_constellation")
INDEX_DIR.mkdir(exist_ok=True, parents=True)


# ================================================================
# æ­£è¦åŒ– + æ—¥æœ¬èªãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºï¼ˆæˆæ¥­æº–æ‹ ï¼šfugashiä½¿ç”¨ï¼‰
# ================================================================

_tagger = Tagger()  # å¿…è¦ãªã‚‰ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¯ã“ã“ã§èª¿æ•´

def normalize(text: str) -> str:
    """ç°¡å˜ãªæ­£è¦åŒ–ï¼ˆã‚¹ãƒšãƒ¼ã‚¹é¡ã‚’æ•´ç†ï¼‰"""
    if not text:
        return ""
    t = text.replace("\u3000", " ")
    t = re.sub(r"[\t\r\n]+", " ", t)
    t = re.sub(r"[ ]{2,}", " ", t)
    return t.strip()


def tokenize_ja(text: str):
    """
    æˆæ¥­ãƒãƒ¼ãƒˆã¨åŒã˜ç™ºæƒ³ã§ã€fugashi(MeCab)ã§åˆ†ã‹ã¡æ›¸ãã€‚
    è¨˜å·ãƒ»è‹±æ•°å­—ã ã‘ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¯è½ã¨ã™ã€‚
    """
    text = normalize(text)
    tokens = []
    for w in _tagger(text):
        s = w.surface.strip()
        if not s:
            continue
        # è‹±æ•°å­—ãƒ»è¨˜å·ã®ã¿ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é™¤å¤–
        if re.match(r"^[0-9A-Za-z!-/:-@[-`{-~]+$", s):
            continue
        tokens.append(s)
    return tokens


# ================================================================
# æ¤œç´¢ç”¨ãƒ†ã‚­ã‚¹ãƒˆã®æ§‹ç¯‰
# myth_summary + keywords + best_months ã‚’1æœ¬ã®æ–‡å­—åˆ—ã«ã™ã‚‹
# ================================================================

def build_index_text(entry: dict) -> str:
    """
    æ˜Ÿåº§1ä»¶åˆ†ã®ã‚¨ãƒ³ãƒˆãƒªã‹ã‚‰ã€BM25ç”¨ã® index_text ã‚’ç”Ÿæˆã€‚
    - myth_summary
    - keywords
    - best_monthsï¼ˆä¾‹: 11,12,1 â†’ "11æœˆ 12æœˆ 1æœˆ"ï¼‰
    """
    parts = []

    myth = entry.get("myth_summary", "")
    if myth:
        parts.append(myth)

    keywords = entry.get("keywords", [])
    if keywords:
        parts.append(" ".join(keywords))

    months = entry.get("best_months", [])
    if months:
        month_tokens = [f"{m}æœˆ" for m in months]
        parts.append(" ".join(month_tokens))

    return "ã€‚".join(parts)


# ================================================================
# è»¢ç½®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ + BM25ï¼ˆæˆæ¥­ãƒãƒ¼ãƒˆæº–æ‹ ï¼‰
# ================================================================

class InvertedIndexArray:
    def __init__(self):
        self.vocab = []
        self.postings = {}   # term -> [(doc_id, tf), ...]
        self.doc_count = 0
        self.avgdl = 0.0
        self.doc_lens = []

    def build(self, docs):
        """TFä»˜ãè»¢ç½®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰"""
        self.doc_count = len(docs)
        vocab_set = set()
        postings = {}
        self.doc_lens = []

        for doc_id, doc in enumerate(docs):
            tokens = tokenize_ja(doc)
            tf_counts = Counter(tokens)
            self.doc_lens.append(len(tokens))

            for term, tf in tf_counts.items():
                vocab_set.add(term)
                postings.setdefault(term, []).append((doc_id, tf))

        self.avgdl = sum(self.doc_lens) / max(1, len(self.doc_lens))
        self.vocab = sorted(vocab_set)

        # doc_idé †ã«æ•´åˆ—ï¼ˆãªãã¦ã‚‚å‹•ããŒä¸€å¿œæƒãˆã¦ãŠãï¼‰
        for t in postings:
            postings[t] = sorted(postings[t], key=lambda x: x[0])
        self.postings = postings

    def bm25(self, query_terms, k1=1.5, b=0.75):
        """BM25ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        scores = {doc_id: 0.0 for doc_id in range(self.doc_count)}

        for term in query_terms:
            plist = self.postings.get(term, [])
            df = len(plist)
            if df == 0:
                continue
            idf = math.log((self.doc_count - df + 0.5) / (df + 0.5) + 1)

            for doc_id, tf in plist:
                dl = self.doc_lens[doc_id]
                denom = tf + k1 * (1 - b + b * dl / self.avgdl)
                score = idf * (tf * (k1 + 1)) / denom
                scores[doc_id] += score

        return scores

    def bm25_search(self, query, topk=10):
        """ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—ã‚’å…¥åŠ›ã—ã¦ä¸Šä½æ–‡æ›¸ã‚’è¿”ã™ï¼ˆdoc_id, score ã®ãƒªã‚¹ãƒˆï¼‰"""
        terms = tokenize_ja(query)
        scores = self.bm25(terms)
        ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        return ranked[:topk]


# ================================================================
# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
# ================================================================

def build_constellation_index():
    """
    constellation_data_with_keywords.json ã‹ã‚‰
    - docs: id -> index_text
    - titles: id -> jp_name
    ã‚’ä½œæˆã—ã€BM25ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ã—ã¦ joblib ã§ä¿å­˜ã™ã‚‹ã€‚
    """
    with open(DATA_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)

    docs = {}    # id -> index_text
    titles = {}  # id -> jp_name

    for entry in data:
        cid = entry["id"]  # ä¾‹: "Orion"
        jp_name = entry.get("jp_name", cid)

        index_text = build_index_text(entry)

        docs[cid] = index_text
        titles[cid] = jp_name

    # docs.values() ã‚’ BM25 ã«ä¸ãˆã‚‹ï¼ˆkeys() ã¨é †ç•ªã‚’æƒãˆã‚‹ï¼‰
    keys = list(docs.keys())
    docs_list = list(docs.values())

    index = InvertedIndexArray()
    index.build(docs_list)

    # æˆæ¥­ãƒãƒ¼ãƒˆã¨åŒã˜ã‚ˆã†ã«4ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ†ã‘ã¦ä¿å­˜
    joblib.dump(index, INDEX_DIR / "bm25_index.joblib")
    joblib.dump(docs_list, INDEX_DIR / "docs.joblib")
    joblib.dump(keys, INDEX_DIR / "keys.joblib")
    joblib.dump(titles, INDEX_DIR / "titles.joblib")

    print(f"âœ… Indexed {len(docs)} constellations")
    print(f"ğŸ“¦ Saved to {INDEX_DIR.resolve()}")


# ================================================================
# ç°¡å˜ãªBM25æ¤œç´¢ãƒ†ã‚¹ãƒˆï¼ˆBM25ã ã‘ï¼‰
# ================================================================

def test_bm25():
    index = joblib.load(INDEX_DIR / "bm25_index.joblib")
    docs_list = joblib.load(INDEX_DIR / "docs.joblib")
    keys = joblib.load(INDEX_DIR / "keys.joblib")
    titles = joblib.load(INDEX_DIR / "titles.joblib")

    query = "å†¬ã®æ˜ã‚‹ã„æ˜ŸãŒç›®ç«‹ã¤æ˜Ÿåº§"
    results = index.bm25_search(query, topk=5)

    print("\n=== BM25 only (test) ===")
    for doc_id, score in results:
        cid = keys[doc_id]
        name = titles.get(cid, cid)
        snippet = docs_list[doc_id][:120].replace("\n", "")
        print(f"- {name} ({cid}) score={score:.3f}")
        print(f"  {snippet}")
        print()


if __name__ == "__main__":
    # â‘  ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆï¼ˆæ¯å›ä¸Šæ›¸ãã§OKï¼‰
    build_constellation_index()

    # â‘¡ ç°¡å˜ãªBM25ãƒ†ã‚¹ãƒˆ
    test_bm25()
